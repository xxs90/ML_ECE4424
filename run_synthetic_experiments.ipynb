{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from crossval import cross_validate\n",
    "from mlp import mlp_train, mlp_predict, logistic, nll\n",
    "from kernelsvm import kernel_svm_train, kernel_svm_predict\n",
    "from scipy.io import loadmat\n",
    "from plotutils import plot_data, plot_surface\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load synthetic binary-class data from MATLAB data file\n",
    "\n",
    "variables = dict()\n",
    "loadmat('syntheticData.mat', variables)\n",
    "\n",
    "# use some list comprehensions to clean up MATLAB data conversion\n",
    "train_labels = [vector[0].ravel() for vector in variables['trainLabels']]\n",
    "train_data = [matrix[0] for matrix in variables['trainData']]\n",
    "test_labels = [vector[0].ravel() for vector in variables['testLabels']]\n",
    "test_data = [matrix[0] for matrix in variables['testData']]\n",
    "\n",
    "# set constants for convenience\n",
    "\n",
    "num_datasets = len(train_labels)\n",
    "num_models = 5\n",
    "num_folds = 4\n",
    "\n",
    "# initialize matrix to store test accuracies\n",
    "test_accuracy = np.zeros((num_datasets, num_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot training data\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    plt.figure()\n",
    "    plot_data(train_data[i], train_labels[i])\n",
    "    plt.title('Dataset %d' % i)\n",
    "    plt.xlabel('x[0]')\n",
    "    plt.ylabel('x[1]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run multi-layer perceptron with cross-validation to select model parameters and structure on all datasets\n",
    "# this will take a few minutes\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    structures = [[1], [4], [2, 2], [2, 4], [4, 4]]\n",
    "    lambda_vals = [0.01, 0.1, 1]\n",
    "    \n",
    "    params = {\n",
    "        'max_iter': 400,\n",
    "        'activation_function': logistic,\n",
    "        'loss_function': nll\n",
    "    }\n",
    "    \n",
    "    best_params = []\n",
    "    best_score = 0\n",
    "    \n",
    "    for j in range(len(structures)):\n",
    "        for k in range(len(lambda_vals)):\n",
    "            params['num_hidden_units']= structures[j]\n",
    "            params['lambda'] = lambda_vals[k]\n",
    "            \n",
    "            cv_score, models = cross_validate(mlp_train, mlp_predict, train_data[i], train_labels[i], num_folds, params)\n",
    "            \n",
    "            if cv_score > best_score:\n",
    "                best_score = cv_score\n",
    "                best_params = copy.copy(params)\n",
    "                \n",
    "    mlp_model = mlp_train(train_data[i], train_labels[i], best_params)\n",
    "    predictions, _, _, _ = mlp_predict(test_data[i], mlp_model)\n",
    "    test_accuracy[i, 0] = np.mean(predictions == test_labels[i])\n",
    "    \n",
    "    print(\"MLP had test accuracy %f on Dataset %d\" % (test_accuracy[i, 0], i))\n",
    "    print(\"with structure %s and lambda = %f\" % (repr(best_params['num_hidden_units']), best_params['lambda']))\n",
    "    \n",
    "    plt.figure()\n",
    "    plot_surface(mlp_predict, mlp_model, train_data[i])\n",
    "    plot_data(train_data[i], train_labels[i])\n",
    "    plt.title('MLP on Dataset %d' % i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run linear SVM\n",
    "\n",
    "c_vals = 10 ** np.linspace(-3, 1, 5)\n",
    "\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    best_params = []\n",
    "    best_score = 0\n",
    "\n",
    "    for j in range(len(c_vals)):\n",
    "        params = {\n",
    "            'kernel': 'linear',\n",
    "            'C': c_vals[j]\n",
    "        }\n",
    "        \n",
    "        cv_score, _ = cross_validate(kernel_svm_train, kernel_svm_predict, train_data[i], train_labels[i], num_folds, params)\n",
    "        \n",
    "        if cv_score > best_score:\n",
    "            best_score = cv_score\n",
    "            best_params = params\n",
    "            \n",
    "    lin_svm_model = kernel_svm_train(train_data[i], train_labels[i], best_params)\n",
    "    predictions, _ = kernel_svm_predict(test_data[i], lin_svm_model)\n",
    "    test_accuracy[i, 1] = np.mean(predictions == test_labels[i])\n",
    "    \n",
    "    print(\"Linear SVM had test accuracy %f on Dataset %d\" % (test_accuracy[i, 1], i))\n",
    "    print(\"with C = %f\" % (best_params['C']))\n",
    "    \n",
    "    plt.figure()\n",
    "    plot_surface(kernel_svm_predict, lin_svm_model, train_data[i])\n",
    "    plot_data(train_data[i], train_labels[i])\n",
    "    plt.title('Linear SVM on Dataset %d' % i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run polynomial SVM\n",
    "\n",
    "c_vals = 10 ** np.linspace(-3, 1, 5)\n",
    "orders = [2, 3, 4]\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    best_params = []\n",
    "    best_score = 0\n",
    "    \n",
    "    for j in range(len(c_vals)):\n",
    "        for k in range(len(orders)):\n",
    "            params = {\n",
    "                'kernel': 'polynomial',\n",
    "                'C': c_vals[j],\n",
    "                'order': orders[k]\n",
    "            }\n",
    "            \n",
    "            cv_score, _ = cross_validate(kernel_svm_train, kernel_svm_predict, train_data[i], train_labels[i], num_folds, params)\n",
    "            \n",
    "            if cv_score > best_score:\n",
    "                best_score = cv_score\n",
    "                best_params = params\n",
    "            \n",
    "    poly_svm_model = kernel_svm_train(train_data[i], train_labels[i], best_params)\n",
    "    predictions, _ = kernel_svm_predict(test_data[i], poly_svm_model)\n",
    "    test_accuracy[i, 2] = np.mean(predictions == test_labels[i])\n",
    "    \n",
    "    print(\"Polynomial SVM had test accuracy %f on Dataset %d\" % (test_accuracy[i, 2], i))\n",
    "    print(\"with C = %f, order = %d\" % (best_params['C'], best_params['order']))\n",
    "    \n",
    "    plt.figure()\n",
    "    plot_surface(kernel_svm_predict, poly_svm_model, train_data[i])\n",
    "    plot_data(train_data[i], train_labels[i])\n",
    "    plt.title('Polynomial SVM on Dataset %d' % i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run RBF SVM\n",
    "\n",
    "c_vals = 10 ** np.linspace(-3, 3, 7)\n",
    "sigmas = np.linspace(0.1, 1.5, 15)\n",
    "\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    best_params = []\n",
    "    best_score = 0\n",
    "\n",
    "    for j in range(len(c_vals)):\n",
    "        for k in range(len(sigmas)):\n",
    "            params = {\n",
    "                'kernel': 'rbf',\n",
    "                'C': c_vals[j],\n",
    "                'sigma': sigmas[k]\n",
    "            }\n",
    "            \n",
    "            cv_score, _ = cross_validate(kernel_svm_train, kernel_svm_predict, train_data[i], train_labels[i], num_folds, params)\n",
    "            \n",
    "            if cv_score > best_score:\n",
    "                best_score = cv_score\n",
    "                best_params = params\n",
    "                \n",
    "    rbf_svm_model = kernel_svm_train(train_data[i], train_labels[i], best_params)\n",
    "    predictions, _ = kernel_svm_predict(test_data[i], rbf_svm_model)\n",
    "    test_accuracy[i, 3] = np.mean(predictions == test_labels[i])\n",
    "    \n",
    "    print(\"RBF SVM had test accuracy %f on Dataset %d\" % (test_accuracy[i, 3], i))\n",
    "    print(\"with C = %f, sigma = %f\" % (best_params['C'], best_params['sigma']))\n",
    "    \n",
    "    plt.figure()\n",
    "    plot_surface(kernel_svm_predict, rbf_svm_model, train_data[i])\n",
    "    plot_data(train_data[i], train_labels[i])\n",
    "    plt.title('RBF SVM on Dataset %d' % i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy table\n",
    "\n",
    "methods = ['MLP\\t', 'LinSVM\\t', 'PolySVM\\t', 'RBFSVM\\t']\n",
    "\n",
    "print((\" \" * 10) + \"TEST ACCURACIES (Percent)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Set\\t   \" + \"   \".join([\"%d\" % number for number in range(num_datasets)]))\n",
    "print(\"-\" * 50)\n",
    "for i in range(len(methods)):\n",
    "    line = [methods[i]]\n",
    "    for j in range(num_datasets):\n",
    "        line += [\"%d\" % (100 * test_accuracy[j, i])]\n",
    "    print(\"  \".join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
